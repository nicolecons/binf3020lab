{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINF3020 Lab 1 â€“ Expression data analysis in Python: Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Last revision:Wed 29 Oct 2025 22:31:42 AEDT.*  Revised version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:90% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab/homework activity, you will answer some questions on topics from lectures and learn how to apply some of the techniques covered to representative datasets. We will be working with a number of microarray datasets and working on data preparation, cluster analysis and classification learning. You need to work through the notebook and complete the answers to questions in the notebook cells.\n",
    "\n",
    "#### Please ensure each answer is completed in the single cell of the notebook immediately following the question, and that all answers are in ```markdown``` format !!!\n",
    "\n",
    "Once you have completed the notebook, make sure you save it with the filename \"Lab1_Solutions.ipynb\" and submit it via Moodle.\n",
    "\n",
    "All questions are worth 1 mark, so there are a total of *10 marks* available.\n",
    "\n",
    "Total notebook marks will be scaled to a **course mark out of 5** to contribute to your course total.\n",
    "\n",
    "**Deadline: 23:55pm, Monday November 10, 2025**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your environment should have already been set up to enable to run this notebook if you successfully completed the lab \"Lab1_Intro_Python.ipynb\". The main data structure we will be using is the ```DataFrame``` (something you are probably familiar with from R). The principal toolkit for handling DataFrames in Python is a library called ```Pandas```. You can find some useful information in compact form on basic use of [Pandas](https://towardsdatascience.com/how-to-master-pandas-8514f33f00f6) and another one on some more [advanced uses](https://towardsdatascience.com/learn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, whenever we get some data given to us we will start by doing some basic exploration (\"know your data\"). This will give us an idea of what is in the data and what types of analysis we may be able to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "df_train = pd.read_csv(\"./datasets/ALL_AML_train.csv\")\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, there are over 7,000 rows and 78 columns. From our knowledge of microarray data we would assume that the shape of this data frame suggests the rows correspond to genes and the columns to samples. Let us transpose the dataset and look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be Affymetrix data. \n",
    "However, it also looks like this dataset needs to be \"cleaned\" before starting any analysis, so that is what we will do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Read in the training and test datasets\n",
    "train_dataset = pd.read_csv('./datasets/ALL_AML_train.csv')\n",
    "test_dataset  = pd.read_csv('./datasets/ALL_AML_test.csv')\n",
    "\n",
    "train_dataset1 = [col for col in train_dataset.columns if \"call\" not in col]\n",
    "train_dataset  = train_dataset[train_dataset1]\n",
    "\n",
    "test_dataset1 = [col for col in test_dataset.columns if \"call\" not in col]\n",
    "test_dataset  = test_dataset[test_dataset1]\n",
    "\n",
    "train_dataset = train_dataset.T\n",
    "test_dataset = test_dataset.T\n",
    "\n",
    "train_dataset2 = train_dataset.drop(['Gene Description','Gene Accession Number'],axis=0)\n",
    "test_dataset2  = test_dataset.drop(['Gene Description','Gene Accession Number'],axis=0)\n",
    "\n",
    "# Ensure data frame entries are numeric and indexing has the same order\n",
    "train_dataset2.index = pd.to_numeric(train_dataset2.index)\n",
    "train_dataset2.sort_index(inplace=True)\n",
    "\n",
    "test_dataset2.index = pd.to_numeric(test_dataset2.index)\n",
    "test_dataset2.sort_index(inplace=True)\n",
    "\n",
    "print(f'Dataset sizes: ')\n",
    "print(f'Training set: {train_dataset2.shape}')\n",
    "print(f'Test set: {test_dataset2.shape}')\n",
    "\n",
    "# Read in the classes and inspect the structure of the data\n",
    "y = pd.read_csv('./datasets/ALL_AML_classes.csv')\n",
    "print(f'Class distribution: ')\n",
    "print(y['cancer'].value_counts())\n",
    "y = y.replace({'ALL':0,'AML':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some pre-processing to make sure the data is in a suitable format for the sklearn algorithms we will use, and also to scale the gene expression values as a normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "X_train = train_dataset2.reset_index(drop=True)\n",
    "Y_train = y[y.patient <= 38].reset_index(drop=True)\n",
    "\n",
    "# Test set\n",
    "X_test = test_dataset2.reset_index(drop=True)\n",
    "Y_test = y[y.patient > 38].reset_index(drop=True)\n",
    "\n",
    "Y_test = Y_test.iloc[:,1].values\n",
    "Y_train = Y_train.iloc[:,1].values\n",
    "\n",
    "# refer to the Scikit-learn documentation to understand how StandardScaler works\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is very high-dimensional and we only have a relatively small number of samples we will apply _dimensionality reduction_ using PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What does it mean to say that a dataset \"is very high-dimensional\" ?**\n",
    "\n",
    "1. The dataset has a small number of samples and a small number of features\n",
    "2. The dataset has a small number of samples and a large number of features\n",
    "3. The dataset has a large number of samples and a small number of features\n",
    "4. The dataset has a large number of samples and a large number of features\n",
    "5. I have a different interpretation (write a sentence below explaining why you selected this answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 answer.**   _Your answer goes here._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn to address the issue of high-dimensionality with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = None)\n",
    "X_train_pca = pca.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the \"explained variance\" of each principal component, up to 90% of the total variance\n",
    "total = sum(pca.explained_variance_)\n",
    "k = 0\n",
    "current_variance = 0\n",
    "while current_variance/total < 0.90:\n",
    "      current_variance += pca.explained_variance_[k]\n",
    "      k = k + 1\n",
    "k\n",
    "\n",
    "# Applying PCA to select the top k components capturing up to 90% of the variance\n",
    "pca = PCA(n_components = k)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "var_exp = pca.explained_variance_ratio_.cumsum()\n",
    "var_exp = var_exp*100\n",
    "\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(f'PCA Dim: {k}; PCA Var: {var1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. what is the reduction in the number of dimensions if we use the PCA transformed data instead of the original ?**\n",
    "\n",
    "1. 28\n",
    "2. 38\n",
    "3. 72\n",
    "4. 7101\n",
    "5. 7129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 answer.**   _Your answer goes here._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3. In your own words, briefly explain what inference can be drawn from the results of this application of PCA to the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 answer.**   _Your answer goes here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to visualize the data following this transform, we select only the first two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "\n",
    "# plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1],c=Y_train, edgecolor='none', alpha=0.9, cmap=plt.cm.get_cmap('Spectral', 10))\n",
    "\n",
    "# 'Qualitative' 'Setl'\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1],c=Y_train, edgecolor='none', alpha=0.9, cmap=matplotlib.colormaps['Accent'])\n",
    "\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.title('Separation of classes by first two principal components')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.  In your opinion, which of the following is the best explanation of the plot of the separation of the two classes when the data are projected only onto the first two principal components ?**\n",
    "\n",
    "1. There is good class separation due to the large amount of explained variance from the first two principal components\n",
    "2. There is only limited class separation although there is a large amount of explained variance from the first two principal components\n",
    "3. There is good class separation although there is only a limited amount of explained variance from the first two principal components\n",
    "4. There is only limited class separation due to the limited amount of explained variance from the first two principal components\n",
    "5. None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4 answer.**   _Your answer goes here._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could apply one of the methods designed to reduce dimensionality \"automatically\" to a pre-defined number of dimensions (Self-Organizing Maps, discussed in lectures, is one such method). Methods designed to enable visualisation, map input data to two dimensions. One such method is [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), which we will use to provde another perspective on the data. You can find more information on t-SNE [here](https://lvdmaaten.github.io/tsne/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "X = X_train\n",
    "tsne = manifold.TSNE(n_components=2, init=\"random\", random_state=0, perplexity=3)\n",
    "res = tsne.fit_transform(X)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(res[:, 0], res[:, 1], c=Y_train, edgecolor='none', alpha=0.9, cmap=matplotlib.colormaps['Accent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Do you think the results from applying tSNE to the original data are consistent with your answer to Q4 ? Answer yes or no, and provide a one-sentence justification for your choice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5 answer.**  _Your answer goes here._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two options here. On one hand, now we know that dimensionality can be reduced, for example by PCA, we can try a standard linear classifier. However, since the data will be transformed by such dimensionality reduction it is not clear how this new representation relates to the original gene expression dataset. On the other hand, we could try a more powerful \"black-box\" classifier, such as ensemble learning using boosting on the original data, and see how that turns out.\n",
    "\n",
    "To evaluate and compare two classifiers we will apply several widely-used metrics. First is the predictive accuracy of each classifer on the test set. Second, the 2x2 [confusion matrices](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) for the test set predictions are generated. Third, the [Mathews correlation coefficient (MCC)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) is computed from the confusion matrices for both classifiers.\n",
    "\n",
    "If you are not familiar with confusion matrices, here is the format of the confusion matrix evaluating a two-class predictive classifier, where the classes are denoted \"positive\" (Pos) and \"negative\" (Neg), although these are simply arbitrary labels. You can find more information on confusion matrices [here](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "| Actual | Predicted |   |\n",
    "| :---   | :---: | :---: |\n",
    "|        | Pos   | Neg   |\n",
    "| Pos    | TP    | FN    |\n",
    "| Neg    | FP    | TN    |\n",
    "\n",
    "\n",
    "The Mathews correlation coefficient is often used in bioinformatics applications of machine learning as a single metric summarising the results in a confusion matrix. Useful information is in the Introduction of this [article](https://www.frontiersin.org/articles/10.3389/frobt.2022.876814/full) and more detail is in this [Wikipedia article](https://en.wikipedia.org/wiki/Phi_coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a logistic regression classifier to the PCA-transformed version of the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf=LogisticRegression(penalty='l2',solver='liblinear',random_state=0)\n",
    "clf.fit(X_train_pca,Y_train)\n",
    "\n",
    "Y_pred=clf.predict(X_test_pca)\n",
    "\n",
    "log_reg_ac = accuracy_score(Y_test, Y_pred)\n",
    "log_reg_cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy: {log_reg_ac}')\n",
    "print(log_reg_cm)\n",
    "\n",
    "matthews_corrcoef(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a gradient-boosting classifier to the training set\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "grad_boost_ac = accuracy_score(Y_test, Y_pred)\n",
    "grad_boost_cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(f'Gradient Boosting Accuracy: {grad_boost_ac}')\n",
    "print(grad_boost_cm)\n",
    "\n",
    "matthews_corrcoef(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6 [1 mark]. From these results, what can you say about which classifier may be \"better\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6 answer.**   _Your answer goes here. [HINT: compare both accuracies]_  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7 [1 mark]. With reference to the materials above on confusion matrices, etc. provide some commentary on any further insight you might obtain about the relative performance of the two classification methods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7 answer.** _Your answer goes here. [HINT: think about what may be going on beyond accuracy]_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning our attention back to unsupervised learning, we start by loading the Yeast cell-cycle time series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spellman dataset\n",
    "df_sc = pd.read_csv(\"./datasets/gene800_Spellman.csv\")\n",
    "df_sc.shape\n",
    "df_sc.info()\n",
    "df_sc.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sc = df_sc.T\n",
    "train_sc2 = train_sc.drop(['gene_name'], axis=0)\n",
    "train_sc2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before clustering, try a visualization with t_SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_sc = manifold.TSNE(n_components=2, init=\"random\", random_state=0, perplexity=10)\n",
    "res_sc = tsne_sc.fit_transform(train_sc2.T)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(res_sc[:, 0], res_sc[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8. What can you infer about the possibility of finding a good clustering of this data from the t-SNE visualization ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8 answer.**   _Your answer goes here._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km_sc = KMeans(n_clusters=10, n_init=10)\n",
    "km_sc.fit(train_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "for k in range(2,20):\n",
    "    km_sc = KMeans(n_clusters=k, n_init=10)\n",
    "#     km_sc.fit(train_sc2)\n",
    "    km_sc.fit(train_sc2.T)\n",
    "    lb_sc = km_sc.labels_\n",
    "#     ss = metrics.silhouette_score(train_sc2, lb_sc, metric='sqeuclidean')\n",
    "    ss = metrics.silhouette_score(train_sc2.T, lb_sc, metric='sqeuclidean')\n",
    "    print(f'K = {k}, Silhouette score = {ss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. Which setting for \"k\" achieves the best clustering ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9 answer.**   _Your answer goes here._ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels for the NCI60 dataset\n",
    "df_nci_lb = pd.read_csv(\"./datasets/nci60_labs.csv\")\n",
    "print(df_nci_lb.shape)\n",
    "df_nci_lb.x.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the microarray data for the NCI60 dataset\n",
    "df_nci_dat = pd.read_csv(\"./datasets/nci60_data.csv\")\n",
    "print(df_nci_dat.shape)\n",
    "print(df_nci_dat.T.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_nci_X = df_nci_dat.iloc[0:64,1:6831]\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "avg = AgglomerativeClustering(linkage='average', metric='euclidean', n_clusters=20) \n",
    "avg.fit(df_nci_X)\n",
    "\n",
    "nci_lbls = avg.labels_\n",
    "\n",
    "nci_ss = metrics.silhouette_score(df_nci_X, nci_lbls, metric='sqeuclidean')\n",
    "print(f'Silhouette score = {nci_ss}')\n",
    "\n",
    "linkages = ['average', 'single', 'complete', 'ward']\n",
    "for link_type in linkages:\n",
    "    avg = AgglomerativeClustering(linkage=link_type, metric='euclidean', n_clusters=10)\n",
    "    avg.fit(df_nci_X)\n",
    "    nci_lbls = avg.labels_\n",
    "    nci_ss = metrics.silhouette_score(df_nci_X, nci_lbls, metric='sqeuclidean')\n",
    "    print(f'Silhouette score = {nci_ss}')\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10. Can you find a better clustering by changing the number of clusters (set by the 'n_clusters=' parameter ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10 answer.** _Add your code in the cell below and run it to generate output for the silhouette scores._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
